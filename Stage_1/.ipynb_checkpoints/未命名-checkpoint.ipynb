{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0/99\n",
      "-*-*-*-*-*-*-*-*-*-*\n",
      "../Dataset/train\\chickens\\chickens098.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits037.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits135.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens303.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits136.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits108.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens276.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens180.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens031.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens251.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens249.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens182.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens244.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits205.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens284.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens018.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens247.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits250.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits056.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens109.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens138.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits089.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits050.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens013.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens121.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens240.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens089.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens285.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens113.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens267.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens092.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens196.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens280.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens000.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens037.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits293.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits054.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens201.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens223.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens036.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens241.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits116.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits141.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits007.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens198.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens012.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens243.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens002.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits038.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens258.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits167.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits139.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits125.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits142.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits160.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits173.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits283.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits214.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits174.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits014.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits052.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens061.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens252.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens123.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits244.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits041.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens245.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits275.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens143.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits029.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens261.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits276.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens088.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits015.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits023.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits099.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits295.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits006.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens232.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits093.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits253.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens116.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits264.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits079.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits271.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits121.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens052.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits003.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens297.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens122.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits308.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens217.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits087.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens150.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits031.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits082.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits203.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens127.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits168.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens044.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens094.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens126.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens026.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens250.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits200.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits206.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits239.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits068.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits287.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens091.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens169.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens131.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits019.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits211.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits219.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens009.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens187.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens189.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens269.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens308.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits285.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits094.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens174.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens106.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits080.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens166.jpg  does not exist!\n",
      "../Dataset/train\\chickens\\chickens192.jpg  does not exist!\n",
      "../Dataset/train\\rabbits\\rabbits208.jpg  does not exist!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c081c1875cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Decay LR by a factor of 0.1 every 1 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccuracy_list_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c081c1875cc0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mcorrects_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;31m#print(phase+' processing: {}th batch.'.format(idx))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;31m# 将数据存在gpu或者cpu上\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch37/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from Classes_Network import *\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "ROOT_DIR = '../Dataset/'\n",
    "TRAIN_DIR = 'train/'\n",
    "VAL_DIR = 'val/'\n",
    "TRAIN_ANNO = 'Classes_train_annotation.csv'\n",
    "VAL_ANNO = 'Classes_val_annotation.csv'\n",
    "CLASSES = ['Mammals','Birds']\n",
    "\n",
    "class MyDataset():\n",
    "\n",
    "    def __init__(self, root_dir, annotations_file, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations_file = annotations_file\n",
    "        self.transform = transform\n",
    "\n",
    "        if not os.path.isfile(self.annotations_file):\n",
    "            print(self.annotations_file + 'does not exist!')\n",
    "        self.file_info = pd.read_csv(annotations_file, index_col=0)\n",
    "        self.size = len(self.file_info)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.file_info['path'][idx]\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(image_path + '  does not exist!')\n",
    "            return None\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label_class = int(self.file_info.iloc[idx]['classes'])\n",
    "\n",
    "        sample = {'image': image, 'classes': label_class}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(image)\n",
    "        return sample\n",
    "\n",
    "#存好数据后，开始为训练网络做准备，在深度学习训练中，\n",
    "#一般会对数据进行一些变换，比如：翻转，旋转等等，用来增强鲁棒性，\n",
    "# 因此，这里需要定义一个数据变换函数,这里只做了训练图像的resize和随机水平翻转变换\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((500, 500)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "val_transforms = transforms.Compose([transforms.Resize((500, 500)),\n",
    "                                     transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "train_dataset = MyDataset(root_dir= ROOT_DIR + TRAIN_DIR,\n",
    "                          annotations_file= TRAIN_ANNO,\n",
    "                          transform=train_transforms)\n",
    "\n",
    "test_dataset = MyDataset(root_dir= ROOT_DIR + VAL_DIR,\n",
    "                         annotations_file= VAL_ANNO,\n",
    "                         transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset)\n",
    "data_loaders = {'train': train_loader, 'val': test_loader}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def visualize_dataset():\n",
    "    print(len(train_dataset))\n",
    "    idx = random.randint(0, len(train_dataset))\n",
    "    sample = train_loader.dataset[idx]\n",
    "    print(idx,sample['image'].shape,CLASSES[sample['classes']])\n",
    "    img = sample['image']\n",
    "    plt.imshow(transforms.ToPILImage()(img))\n",
    "    plt.show()\n",
    "visualize_dataset()\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    Loss_list = {'train': [], 'val': []}\n",
    "    Accuracy_list_classes = {'train': [], 'val': []}\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # epoch循环训练\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-*' * 10)\n",
    "\n",
    "        # 每个epoch都有train(训练)和val(测试)两个阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects_classes = 0\n",
    "\n",
    "            for idx,data in enumerate(data_loaders[phase]):\n",
    "                #print(phase+' processing: {}th batch.'.format(idx))\n",
    "                # 将数据存在gpu或者cpu上\n",
    "                inputs = data['image'].to(device)\n",
    "                labels_classes = data['classes'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    x_classes = model(inputs)\n",
    "\n",
    "                    x_classes = x_classes.view(-1, 2)\n",
    "\n",
    "                    _, preds_classes = torch.max(x_classes, 1)\n",
    "                    # 计算训练误差\n",
    "                    loss = criterion(x_classes, labels_classes)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                corrects_classes += torch.sum(preds_classes == labels_classes)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loaders[phase].dataset)\n",
    "            Loss_list[phase].append(epoch_loss)\n",
    "\n",
    "            epoch_acc_classes = corrects_classes.double() / len(data_loaders[phase].dataset)\n",
    "            epoch_acc = epoch_acc_classes\n",
    "\n",
    "            Accuracy_list_classes[phase].append(100 * epoch_acc_classes)\n",
    "            print('{} Loss: {:.4f}  Acc_classes: {:.2%}'.format(phase, epoch_loss,epoch_acc_classes))\n",
    "            # 测试阶段\n",
    "            # 如果当前epoch下的准确率总体提高或者误差下降，则认为当下的模型最优\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "\n",
    "                best_acc = epoch_acc_classes\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best val classes Acc: {:.2%}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'best_model.pt')\n",
    "    print('Best val classes Acc: {:.2%}'.format(best_acc))\n",
    "    return model, Loss_list,Accuracy_list_classes\n",
    "\n",
    "#函数定义好后，设置参数并调用\n",
    "network = Net().to(device)\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1) # Decay LR by a factor of 0.1 every 1 epochs\n",
    "model, Loss_list, Accuracy_list_classes = train_model(network, criterion, optimizer, exp_lr_scheduler, num_epochs=100)\n",
    "\n",
    "\n",
    "#为了更方便的观察模型的训练过程，可以将它可视化，使用matplotlib即可\n",
    "x = range(0, 100)\n",
    "y1 = Loss_list[\"val\"]\n",
    "y2 = Loss_list[\"train\"]\n",
    "\n",
    "plt.plot(x, y1, color=\"r\", linestyle=\"-\", marker=\"o\", linewidth=1, label=\"val\")\n",
    "plt.plot(x, y2, color=\"b\", linestyle=\"-\", marker=\"o\", linewidth=1, label=\"train\")\n",
    "plt.legend()\n",
    "plt.title('train and val loss vs. epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(\"train and val loss vs epoches.jpg\")\n",
    "plt.close('all') # 关闭图 0\n",
    "\n",
    "y5 = Accuracy_list_classes[\"train\"]\n",
    "y6 = Accuracy_list_classes[\"val\"]\n",
    "plt.plot(x, y5, color=\"r\", linestyle=\"-\", marker=\".\", linewidth=1, label=\"train\")\n",
    "plt.plot(x, y6, color=\"b\", linestyle=\"-\", marker=\".\", linewidth=1, label=\"val\")\n",
    "plt.legend()\n",
    "plt.title('train and val Classes_acc vs. epoches')\n",
    "plt.ylabel('Classes_accuracy')\n",
    "plt.savefig(\"train and val Classes_acc vs epoches.jpg\")\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "#另外，还有一种可视化方法，将图片以及图片的标签和预测结果直接打印出来\n",
    "############################################ Visualization ###############################################\n",
    "def visualize_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loaders['val']):\n",
    "            inputs = data['image']\n",
    "            labels_classes = data['classes'].to(device)\n",
    "\n",
    "            x_classes = model(inputs.to(device))\n",
    "            x_classes=x_classes.view( -1,2)\n",
    "            _, preds_classes = torch.max(x_classes, 1)\n",
    "\n",
    "            print(inputs.shape)\n",
    "            plt.imshow(transforms.ToPILImage()(inputs.squeeze(0)))\n",
    "            plt.title('predicted classes: {}\\n ground-truth classes:{}'.format(CLASSES[preds_classes],CLASSES[labels_classes]))\n",
    "            plt.show()\n",
    "\n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
